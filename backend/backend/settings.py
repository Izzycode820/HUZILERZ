"""
Django settings for backend project.

Generated by 'django-admin startproject' using Django 5.2.5.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/5.2/ref/settings/
"""

from pathlib import Path
import os
from decouple import config
import dj_database_url

# Build paths inside the project like this: BASE_DIR / 'subdir'.
BASE_DIR = Path(__file__).resolve().parent.parent


# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/5.2/howto/deployment/checklist/

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = config('SECRET_KEY')

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = config('DEBUG', default=False, cast=bool)

ALLOWED_HOSTS = config('ALLOWED_HOSTS', default='localhost,127.0.0.1').split(',')


# Application definition

INSTALLED_APPS = [
    'daphne',  # Must be first to override runserver
    'channels',
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    
    # Third party apps
    'rest_framework',
    'corsheaders',
    'graphene_django',
    'django_ratelimit',
    'django_prometheus',
    
    # Local apps - Authentication
    'authentication',
    
    # Local apps - Workspace Core
    'workspace.core',
    'workspace.store',
    'workspace.storefront',
    'workspace.hosting',
    'workspace.blog',
    'workspace.services',
    'workspace.analytics',
    'workspace.sync',
    
    # Template system
   # 'templates',
    
    # Subscription & Billing System
    'subscription',

    # Payments System (multi-provider)
    'payments',

    #Themes & Templates
    'theme',

    #media management
    'medialib',

    # Notifications System
    'notifications',
]

MIDDLEWARE = [
    'corsheaders.middleware.CorsMiddleware',
    'django.middleware.security.SecurityMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'workspace.hosting.middleware.internal_token.InternalTokenMiddleware',  # Internal token auth for health endpoints
    'workspace.storefront.middleware.StoreIdentificationMiddleware',  # Multi-tenant store identification
    'workspace.hosting.middleware.storefront_password.StorefrontPasswordMiddleware',  # Password protection (Concern #2)
    'workspace.hosting.middleware.seo_bot_detection.SEOBotMiddleware',  # Bot detection for SEO (Phase 4)
    'workspace.hosting.middleware.cdn_security.CDNSecurityMiddleware',  # CDN security and cache headers
    'workspace.hosting.middleware.cdn_security.PuckDataRateLimitMiddleware',  # Rate limiting for puck data API
    'workspace.hosting.middleware.WorkspaceRateLimitMiddleware',  # Rate limiting per workspace (Shopify model)
    'workspace.hosting.middleware.bandwidth_tracker.BandwidthTrackingMiddleware',  # Track bandwidth usage per user
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'backend.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

ASGI_APPLICATION = 'backend.asgi.application'
WSGI_APPLICATION = 'backend.wsgi.application'


# Database
# https://docs.djangoproject.com/en/5.2/ref/settings/#databases

# Database configuration with PostgreSQL support
DATABASE_URL = config('DATABASE_URL', default=None)

if DATABASE_URL:
    # Production database from environment
    DATABASES = {
        'default': dj_database_url.parse(DATABASE_URL)
    }
    # Add connection pooling for production
    DATABASES['default']['CONN_MAX_AGE'] = 600  # Keep connections for 10 minutes
    DATABASES['default']['OPTIONS'] = {
        'connect_timeout': 10,
        'options': '-c statement_timeout=30000',  # 30 second query timeout
    }
else:
    # Development database
    DATABASES = {
        'default': {
            'ENGINE': 'django.db.backends.postgresql',
            'NAME': config('DB_NAME'),
            'USER': config('DB_USER'),
            'PASSWORD': config('DB_PASSWORD'),
            'HOST': config('DB_HOST', default='localhost'),
            'PORT': config('DB_PORT', default='5432'),
            # Connection pooling for handling traffic spikes
            'CONN_MAX_AGE': 600,  # Keep connections for 10 minutes
            'OPTIONS': {
                'connect_timeout': 10,
                'options': '-c statement_timeout=30000',  # 30 second query timeout
            }
        }
    }


# Password validation
# https://docs.djangoproject.com/en/5.2/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]


# Internationalization
# https://docs.djangoproject.com/en/5.2/topics/i18n/

LANGUAGE_CODE = 'en-us'

TIME_ZONE = 'UTC'

USE_I18N = True

USE_TZ = True


# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/5.2/howto/static-files/

STATIC_URL = 'static/'

# Default primary key field type
# https://docs.djangoproject.com/en/5.2/ref/settings/#default-auto-field

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'

# Email Configuration
if DEBUG:
    EMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend'
else:
    EMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend'
EMAIL_HOST = 'smtp.gmail.com'
EMAIL_PORT = 587
EMAIL_USE_TLS = True
EMAIL_HOST_USER = os.getenv('EMAIL_HOST_USER', '')
EMAIL_HOST_PASSWORD = os.getenv('EMAIL_HOST_PASSWORD', '')
DEFAULT_FROM_EMAIL = os.getenv('DEFAULT_FROM_EMAIL', 'noreply@huzilerz.com')
SERVER_EMAIL = DEFAULT_FROM_EMAIL

# Email verification settings
EMAIL_VERIFICATION_TOKEN_EXPIRE_HOURS = 24
PASSWORD_RESET_TOKEN_EXPIRE_HOURS = 1

# Redis Configuration
REDIS_HOST = os.getenv('REDIS_HOST', 'localhost')
REDIS_PORT = int(os.getenv('REDIS_PORT', 6379))
REDIS_DB = int(os.getenv('REDIS_DB', 0))
REDIS_PASSWORD = os.getenv('REDIS_PASSWORD', None)

CACHES = {
    'default': {
        'BACKEND': 'django_redis.cache.RedisCache',
        'LOCATION': f'redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}',
        'OPTIONS': {
            'CLIENT_CLASS': 'django_redis.client.DefaultClient',
            'PASSWORD': REDIS_PASSWORD,
        }
    }
}

# Session configuration
SESSION_ENGINE = 'django.contrib.sessions.backends.cache'
SESSION_CACHE_ALIAS = 'default'
SESSION_COOKIE_AGE = 86400  # 24 hours
SESSION_COOKIE_SECURE = not DEBUG
SESSION_COOKIE_HTTPONLY = True
SESSION_COOKIE_SAMESITE = 'Lax'
SESSION_SAVE_EVERY_REQUEST = True

# OAuth2 Configuration
OAUTH2_PROVIDERS = {
    'google': {
        'client_id': os.getenv('GOOGLE_OAUTH2_CLIENT_ID'),
        'client_secret': os.getenv('GOOGLE_OAUTH2_CLIENT_SECRET'),
        'auth_url': 'https://accounts.google.com/o/oauth2/v2/auth',
        'token_url': 'https://oauth2.googleapis.com/token',
        'user_info_url': 'https://www.googleapis.com/oauth2/v2/userinfo',
        'scope': 'openid email profile',
    },
    'apple': {
        'client_id': os.getenv('APPLE_OAUTH2_CLIENT_ID'),
        'team_id': os.getenv('APPLE_OAUTH2_TEAM_ID'),
        'key_id': os.getenv('APPLE_OAUTH2_KEY_ID'),
        'private_key_path': os.getenv('APPLE_OAUTH2_PRIVATE_KEY_PATH'),
        'auth_url': 'https://appleid.apple.com/auth/authorize',
        'token_url': 'https://appleid.apple.com/auth/token',
        'scope': 'name email',
    }
}

OAUTH2_REDIRECT_URI = os.getenv('OAUTH2_REDIRECT_URI', 'http://localhost:3000/auth/oauth2/callback')

# Fapshi Payment Configuration
FAPSHI_SANDBOX_API_USER = config('FAPSHI_SANDBOX_API_USER', default='')
FAPSHI_SANDBOX_API_KEY = config('FAPSHI_SANDBOX_API_KEY', default='')
FAPSHI_SANDBOX_BASE_URL = config('FAPSHI_SANDBOX_BASE_URL', default='https://sandbox.fapshi.com')

FAPSHI_LIVE_API_USER = config('FAPSHI_LIVE_API_USER', default='')
FAPSHI_LIVE_API_KEY = config('FAPSHI_LIVE_API_KEY', default='')
FAPSHI_LIVE_BASE_URL = config('FAPSHI_LIVE_BASE_URL', default='https://api.fapshi.com')

FAPSHI_USE_SANDBOX = config('FAPSHI_USE_SANDBOX', default=True, cast=bool)
FAPSHI_WEBHOOK_SECRET = config('FAPSHI_WEBHOOK_SECRET', default='')
FAPSHI_WEBHOOK_URL_LOCAL = config('FAPSHI_WEBHOOK_URL_LOCAL', default='')
FAPSHI_WEBHOOK_URL_PRODUCTION = config('FAPSHI_WEBHOOK_URL_PRODUCTION', default='')

# Subscription Payment Security
SUBSCRIPTION_PAYMENT_SECRET = config('SUBSCRIPTION_PAYMENT_SECRET', default='change-in-production')

# Twilio WhatsApp Configuration
TWILIO_ENABLED = config('TWILIO_ENABLED', default=False, cast=bool)
TWILIO_ACCOUNT_SID = config('TWILIO_ACCOUNT_SID', default='')
TWILIO_AUTH_TOKEN = config('TWILIO_AUTH_TOKEN', default='')
TWILIO_PHONE_NUMBER = config('TWILIO_PHONE_NUMBER', default='')  # SMS sender number (E.164 format)
TWILIO_WHATSAPP_NUMBER = config('TWILIO_WHATSAPP_NUMBER', default='whatsapp:+14155238886')  # Sandbox number
ADMIN_WHATSAPP_NUMBER = config('ADMIN_WHATSAPP_NUMBER', default='')  # Merchant's WhatsApp (TODO: make workspace-specific)

# GoDaddy Domain Registrar Configuration
DOMAIN_REGISTRAR_MODE = config('DOMAIN_REGISTRAR_MODE', default='mock')  # 'mock' or 'live'
GODADDY_API_KEY = config('GODADDY_API_KEY', default='')
GODADDY_API_SECRET = config('GODADDY_API_SECRET', default='')
GODADDY_SANDBOX = config('GODADDY_SANDBOX', default=True, cast=bool)

# Namecheap Configuration (if needed in future)
NAMECHEAP_API_USER = config('NAMECHEAP_API_USER', default='')
NAMECHEAP_API_KEY = config('NAMECHEAP_API_KEY', default='')
NAMECHEAP_USERNAME = config('NAMECHEAP_USERNAME', default='')
NAMECHEAP_SANDBOX = config('NAMECHEAP_SANDBOX', default=True, cast=bool)

# Domain pricing
USD_TO_FCFA_RATE = config('USD_TO_FCFA_RATE', default='600.00')

# Security Headers and Settings
SECURE_BROWSER_XSS_FILTER = True
SECURE_CONTENT_TYPE_NOSNIFF = True
SECURE_REFERRER_POLICY = 'strict-origin-when-cross-origin'
X_FRAME_OPTIONS = 'DENY'

# HTTPS Settings (Production)
if not DEBUG:
    SECURE_SSL_REDIRECT = True
    SECURE_HSTS_SECONDS = 31536000  # 1 year
    SECURE_HSTS_INCLUDE_SUBDOMAINS = True
    SECURE_HSTS_PRELOAD = True
    SECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https')

# CSRF Settings
CSRF_COOKIE_SECURE = not DEBUG
CSRF_COOKIE_HTTPONLY = True
CSRF_COOKIE_SAMESITE = 'Lax'
CSRF_TRUSTED_ORIGINS = [
    'http://localhost:3000',
    'http://127.0.0.1:3000',
    'https://huzilerz.com',
    'https://*.huzilerz.com'
]

# Content Security Policy
CSP_DEFAULT_SRC = ("'self'",)
CSP_SCRIPT_SRC = ("'self'", "'unsafe-inline'", "https://apis.google.com", "https://appleid.apple.com")
CSP_STYLE_SRC = ("'self'", "'unsafe-inline'", "https://fonts.googleapis.com")
CSP_FONT_SRC = ("'self'", "https://fonts.gstatic.com")
CSP_IMG_SRC = ("'self'", "data:", "https:")
CSP_CONNECT_SRC = ("'self'", "https://api.huzilerz.com")
CSP_FRAME_ANCESTORS = ("'none'",)

# Django REST Framework
REST_FRAMEWORK = {
    'DEFAULT_AUTHENTICATION_CLASSES': [
        'authentication.authentication.JWTAuthentication',
    ],
    'DEFAULT_PERMISSION_CLASSES': [
        'rest_framework.permissions.IsAuthenticated',
    ],
    'DEFAULT_RENDERER_CLASSES': [
        'rest_framework.renderers.JSONRenderer',
    ],
    'DEFAULT_PAGINATION_CLASS': 'rest_framework.pagination.PageNumberPagination',
    'PAGE_SIZE': 20,
    'DEFAULT_FILTER_BACKENDS': [
        'django_filters.rest_framework.DjangoFilterBackend',
        'rest_framework.filters.SearchFilter',
        'rest_framework.filters.OrderingFilter',
    ],
}

# GraphQL Configuration
GRAPHENE = {
    'SCHEMA': 'backend.graphql_schema.schema.schema',
    'MIDDLEWARE': [
        'workspace.storefront.graphql.middleware.tenant_isolation.TenantIsolationMiddleware',  # Must be first for security
        'workspace.storefront.graphql.middleware.complexity.ComplexityMiddleware',
        'workspace.storefront.graphql.middleware.logging.LoggingMiddleware',
        'workspace.storefront.graphql.middleware.error_handler.ErrorHandlerMiddleware',
    ],
    'MAX_QUERY_DEPTH': 10,  # Prevent deep nesting attacks
}

# DataLoader context (for batching)
GRAPHQL_DATALOADERS_ENABLED = True

# CORS Settings
CORS_ALLOWED_ORIGINS = [
    "http://localhost:3000",
    "http://localhost:3001",
    "http://127.0.0.1:3000",
]

CORS_ALLOW_CREDENTIALS = True
CORS_ALLOW_ALL_ORIGINS = DEBUG  # Allow all origins in development
CORS_ALLOW_HEADERS = [
    'accept',
    'accept-encoding',
    'authorization',
    'content-type',
    'dnt',
    'origin',
    'user-agent',
    'x-csrftoken',
    'x-requested-with',
    'x-client-version',
    'x-client-platform',
    'x-workspace-id',
    'x-store-hostname',
]

# CSRF Settings for API
CSRF_TRUSTED_ORIGINS = [
    "http://localhost:3000",
    "http://127.0.0.1:3000",
    "http://192.168.223.169:3000",
]

# Custom User Model
AUTH_USER_MODEL = 'authentication.User'

# JWT Configuration
JWT_SECRET_KEY = config('JWT_SECRET_KEY', default=SECRET_KEY)
JWT_ISSUER = config('JWT_ISSUER', default='hustlerz.camp')  # Issuer claim for JWT tokens
JWT_AUDIENCE = config('JWT_AUDIENCE', default='hustlerz.camp')  # Audience claim for JWT tokens
REFRESH_TOKEN_LIFETIME_DAYS = config('REFRESH_TOKEN_LIFETIME_DAYS', default=7, cast=int)
ACCESS_TOKEN_LIFETIME_MINUTES = config('ACCESS_TOKEN_LIFETIME_MINUTES', default=15, cast=int)

# Internal Health Check Token
# Used for internal health endpoints that require authentication but not user JWT
INTERNAL_HEALTH_TOKEN = config('INTERNAL_HEALTH_TOKEN', default='change-me-in-production')

# Workspace Settings
WORKSPACE_SETTINGS = {
    'MAX_WORKSPACES_PER_USER': 10,
    'ENABLE_WORKSPACE_INVITATIONS': True,
    'DEFAULT_MEMBER_ROLE': 'member',
}

# LOCAL DEVELOPMENT STORAGE SIMULATION
# DEPLOYMENT: Remove these settings for production AWS deployment
USE_LOCAL_HOSTING = config('USE_LOCAL_HOSTING', default=False, cast=bool)
USE_LOCAL_STORAGE = config('USE_LOCAL_STORAGE', default=False, cast=bool)

# INFRASTRUCTURE PROVISIONING MODE
# 'mock': Development mode - no real AWS provisioning, stores mock resource IDs
# 'aws': Production mode - provisions real AWS resources (S3, CloudFront, etc.)
INFRASTRUCTURE_MODE = config('INFRASTRUCTURE_MODE', default='mock')

if USE_LOCAL_STORAGE:
    # Local file storage (simulates S3)
    MEDIA_ROOT = BASE_DIR / 'local_data' / 'media'
    MEDIA_URL = '/media/'

    # MinIO S3-compatible storage for testing S3 integration
    LOCAL_MINIO_ENDPOINT = config('LOCAL_MINIO_ENDPOINT', default='http://localhost:9000')
    LOCAL_MINIO_ACCESS_KEY = config('LOCAL_MINIO_ACCESS_KEY', default='huzilerz_access_key')
    LOCAL_MINIO_SECRET_KEY = config('LOCAL_MINIO_SECRET_KEY', default='huzilerz_secret_key')
else:
    # Production AWS S3 settings (will be configured later)
    # DEFAULT_FILE_STORAGE = 'storages.backends.s3boto3.S3Boto3Storage'
    pass

# Theme Media Configuration
# Serve theme preview images and assets from themes directory
THEMES_ROOT = Path(config('THEMES_BASE_PATH', default=str(BASE_DIR.parent / 'themes'))).resolve()
THEMES_MEDIA_URL = '/theme-media/'  # URL prefix for serving theme files

# Theme CDN URL (Production only - leave None for development)
# In production, set this to your CDN URL: https://cdn.yoursite.com/themes/
THEMES_CDN_URL = config('THEMES_CDN_URL', default=None)

# Local hosting simulation settings
if USE_LOCAL_HOSTING:
    LOCAL_SITES_ROOT = config('LOCAL_SITES_ROOT', default='./local_data/nginx/sites')
    LOCAL_NGINX_CONF_DIR = config('LOCAL_NGINX_CONF_DIR', default='./local_data/nginx/conf')

# Cache Configuration
# Try Redis first, fallback to DummyCache if Redis unavailable
try:
    import redis
    # Test Redis connection
    r = redis.Redis(host=REDIS_HOST, port=REDIS_PORT, db=REDIS_DB, password=REDIS_PASSWORD, socket_connect_timeout=1)
    r.ping()
    # Redis is available
    CACHES = {
        'default': {
            'BACKEND': 'django_redis.cache.RedisCache',
            'LOCATION': f'redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}',
            'OPTIONS': {
                'CLIENT_CLASS': 'django_redis.client.DefaultClient',
                'PASSWORD': REDIS_PASSWORD,
            }
        }
    }
    print("[OK] Using Redis cache")
except Exception as e:
    # Redis unavailable - use DummyCache (no caching, but app continues working)
    CACHES = {
        'default': {
            'BACKEND': 'django.core.cache.backends.dummy.DummyCache',
        }
    }
    print(f"[WARNING] Redis unavailable ({str(e)}), using DummyCache (no caching)")

# Django Channels Configuration (WebSocket support)
CHANNEL_LAYERS = {
    'default': {
        'BACKEND': 'channels_redis.core.RedisChannelLayer',
        'CONFIG': {
            'hosts': [(REDIS_HOST, REDIS_PORT)],
        },
    },
}

# Celery Configuration
CELERY_BROKER_URL = 'redis://localhost:6379/0'
CELERY_RESULT_BACKEND = 'redis://localhost:6379/0'
CELERY_ACCEPT_CONTENT = ['json']
CELERY_TASK_SERIALIZER = 'json'
CELERY_RESULT_SERIALIZER = 'json'
CELERY_TIMEZONE = TIME_ZONE

# Celery configuration for reliability
CELERY_TASK_ROUTES = {
    'workspace.sync.tasks.*': {'queue': 'sync'},
    'workspace.sync.tasks.retry_failed_webhooks_task': {'queue': 'maintenance'},
    'workspace.sync.tasks.health_check_sync_system_task': {'queue': 'monitoring'},
}

# Task execution settings following Shopify patterns
CELERY_TASK_SOFT_TIME_LIMIT = 300  # 5 minutes
CELERY_TASK_TIME_LIMIT = 600      # 10 minutes (hard limit)
CELERY_WORKER_PREFETCH_MULTIPLIER = 1  # One task per worker for reliability
CELERY_TASK_ACKS_LATE = True      # Acknowledge tasks only after completion
CELERY_WORKER_DISABLE_RATE_LIMITS = False
CELERY_RESULT_EXPIRES = 3600      # Delete task results after 1 hour (prevents Redis memory bloat)

# Celery Beat Schedule (Periodic Tasks)
from celery.schedules import crontab

CELERY_BEAT_SCHEDULE = {
    # Domain verification - Every 15 minutes
    'auto-verify-domains': {
        'task': 'workspace_hosting.auto_verify_domains',
        'schedule': 900.0,  # 15 minutes in seconds
        'options': {'queue': 'celery'}
    },

    # SSL certificate provisioning - Every hour
    'provision-ssl-certificates': {
        'task': 'workspace_hosting.provision_ssl_certificates',
        'schedule': 3600.0,  # 1 hour in seconds
        'options': {'queue': 'celery'}
    },

    # Domain health check - Daily at 2:00 AM
    'check-domain-health': {
        'task': 'workspace_hosting.check_domain_health',
        'schedule': crontab(hour=2, minute=0),
        'options': {'queue': 'celery'}
    },

    # Cleanup failed domains - Daily at 3:00 AM
    'cleanup-failed-domains': {
        'task': 'workspace_hosting.cleanup_failed_domains',
        'schedule': crontab(hour=3, minute=0),
        'options': {'queue': 'celery'}
    },

    # Send renewal warnings - Daily at 8:00 AM (morning, when users check email)
    'send-renewal-warnings': {
        'task': 'workspace_hosting.send_renewal_warnings',
        'schedule': crontab(hour=8, minute=0),
        'options': {'queue': 'celery'}
    },

    # Handle expired domains - Daily at 4:00 AM
    'handle-expired-domains': {
        'task': 'workspace_hosting.handle_expired_domains',
        'schedule': crontab(hour=4, minute=0),
        'options': {'queue': 'celery'}
    },

    # Scan overdue workspace deprovisionings - Every hour
    'scan-overdue-deprovisionings': {
        'task': 'workspace_core.scan_overdue_deprovisionings',
        'schedule': 3600.0,  # 1 hour in seconds
        'options': {'queue': 'celery'}
    },

    # Verify workspace roles provisioned - Daily at 3:30 AM
    # Health check: Ensures all workspaces have roles + owner membership
    # Catches edge cases from failed sync provisioning (0.5% failure rate)
    'verify-workspace-roles-provisioned': {
        'task': 'workspace.verify_all_workspaces_roles_provisioned',
        'schedule': crontab(hour=3, minute=30),
        'options': {'queue': 'celery'}
    },

    # Sync bandwidth usage from cache - Every 5 minutes
    'sync-bandwidth-usage': {
        'task': 'workspace_hosting.sync_bandwidth_usage',
        'schedule': 300.0,  # 5 minutes in seconds
        'options': {'queue': 'celery'}
    },

    # Sync storage usage from S3 - Daily at 2:00 AM
    'sync-storage-usage': {
        'task': 'workspace_hosting.sync_storage_usage',
        'schedule': crontab(hour=2, minute=0),
        'options': {'queue': 'celery'}
    },

    # Sync active site counts - Every 15 minutes
    'sync-site-counts': {
        'task': 'workspace_hosting.sync_site_counts',
        'schedule': 900.0,  # 15 minutes in seconds
        'options': {'queue': 'celery'}
    },

    # Enforce limits on overage - Every hour
    'enforce-limits-on-overage': {
        'task': 'workspace_hosting.enforce_limits_on_overage',
        'schedule': 3600.0,  # 1 hour in seconds
        'options': {'queue': 'celery'}
    },

    # Reset monthly bandwidth - 1st of each month at 00:00
    'reset-monthly-bandwidth': {
        'task': 'workspace_hosting.reset_monthly_bandwidth',
        'schedule': crontab(day_of_month='1', hour=0, minute=0),
        'options': {'queue': 'celery'}
    },

    # Capability reconciliation (detects and fixes drift) - Every 5 minutes
    # Catches: Failed tasks, lost signals, manual DB edits, tampering, race conditions
    # Industry best practice: Event-driven (99%) + reconciliation (1% edge cases)
    'reconcile-all-capabilities': {
        'task': 'workspace.reconcile_all_capabilities',
        'schedule': 300.0,  # 5 minutes in seconds (eventual consistency)
        'options': {'queue': 'celery'},
        'kwargs': {
            'auto_fix': True,  # Automatically fix drift (set False for audit-only mode)
            'batch_size': 100  # Process 100 users per run (rate limiting)
        }
    },

    # ===========================
    # PAYMENT TASKS
    # ===========================

    # Reconcile pending payments - Every 5 minutes
    # Webhook fallback: Check for missed webhooks and reconcile with provider
    'reconcile-pending-payments': {
        'task': 'payments.reconcile_pending_payments',
        'schedule': 300.0,  # 5 minutes in seconds
        'options': {'queue': 'celery'}
    },

    # Expire old payments - Every 10 minutes
    # Mark payments as failed after 30-minute timeout (OWASP/PCI DSS)
    'expire-old-payments': {
        'task': 'payments.expire_old_payments',
        'schedule': 600.0,  # 10 minutes in seconds
        'options': {'queue': 'celery'}
    },

    # ===========================
    # SUBSCRIPTION TASKS
    # ===========================

    # Handle expired subscriptions - Daily at 1:00 AM
    # Check for subscriptions past expires_at and start 4-day grace period
    'handle-expired-subscriptions': {
        'task': 'subscription.tasks.handle_expired_subscriptions',
        'schedule': crontab(hour=1, minute=0),
        'options': {'queue': 'celery'}
    },

    # Handle grace period end - Daily at 1:30 AM
    # Auto-downgrade subscriptions to free after grace period ends
    'handle-grace-period-end': {
        'task': 'subscription.tasks.handle_grace_period_end',
        'schedule': crontab(hour=1, minute=30),
        'options': {'queue': 'celery'}
    },

    # Apply pending plan changes - Daily at 2:00 AM
    # Execute scheduled downgrades at billing cycle boundaries
    'apply-pending-plan-changes': {
        'task': 'subscription.tasks.apply_pending_plan_changes',
        'schedule': crontab(hour=2, minute=0),
        'options': {'queue': 'celery'}
    },

    # Cleanup expired plan change requests - Daily at 3:00 AM
    # Remove stale plan change scheduling data
    'cleanup-expired-plan-change-requests': {
        'task': 'subscription.tasks.cleanup_expired_plan_change_requests',
        'schedule': crontab(hour=3, minute=0),
        'options': {'queue': 'celery'}
    },

    # Notify upcoming plan changes - Daily at 8:00 AM
    # Send reminders 7, 3, 1 days before scheduled plan changes
    'notify-upcoming-plan-changes': {
        'task': 'subscription.tasks.notify_upcoming_plan_changes',
        'schedule': crontab(hour=8, minute=0),
        'options': {'queue': 'celery'}
    },

    # Send renewal reminders - Daily at 9:00 AM (Cameroon morning)
    # Send 7-day, 3-day, 1-day renewal reminders for manual payment system
    'send-renewal-reminders': {
        'task': 'subscription.tasks.send_renewal_reminders',
        'schedule': crontab(hour=9, minute=0),
        'options': {'queue': 'celery'}
    },

    # NOTE: send_expiry_day_notifications is covered by renewal_reminders
    # which already handles 1-day, 3-day, and 7-day reminders.

    # Send grace period reminders - Every 12 hours (8 AM and 8 PM)
    # Handles urgency escalation internally (72h, 48h, 24h, 6h remaining)

    # Send grace period reminders - Every 12 hours (8 AM and 8 PM)
    # General reminders for subscriptions in grace period
    'send-grace-period-reminders': {
        'task': 'subscription.tasks.send_grace_period_reminders',
        'schedule': crontab(hour='8,20', minute=0),
        'options': {'queue': 'celery'}
    },

    # Cleanup abandoned data - Weekly on Sunday at 4:00 AM
    # Clean up data for subscriptions suspended 30+ days (fraud/abuse cases)
    'cleanup-abandoned-data': {
        'task': 'subscription.tasks.cleanup_abandoned_data',
        'schedule': crontab(day_of_week='sunday', hour=4, minute=0),
        'options': {'queue': 'celery'}
    },

    # NOTE: create_user_subscription_fallback is NOT scheduled here.
    # It requires user_id argument and is called on-demand when signals fail.
    # The dead letter queue processor below handles recovery of failed creations.

    # Process subscription dead letter queue - Every hour
    # Retry failed subscription creations from DLQ
    'process-subscription-dead-letter-queue': {
        'task': 'subscription.tasks.subscription_creation.process_dead_letter_queue',
        'schedule': 3600.0,  # 1 hour in seconds
        'options': {'queue': 'celery'}
    },

    # Check for expired trials - Daily at 1:15 AM
    # Process trials that have reached expires_at
    'check-trial-expiry': {
        'task': 'subscription.tasks.check_trial_expiry',
        'schedule': crontab(hour=1, minute=15),
        'options': {'queue': 'celery'}
    },

    # ===========================
    # COMPLIANCE TASKS (Downgrade Flow)
    # ===========================

    # Check compliance deadlines - Every hour
    # Process workspaces with expired compliance grace periods
    'check-compliance-deadlines': {
        'task': 'subscription.tasks.compliance_tasks.check_compliance_deadlines',
        'schedule': 3600.0,  # 1 hour in seconds
        'options': {'queue': 'celery'}
    },

    # Handle intro period end - Daily at 1:45 AM
    # Track when intro pricing periods complete
    'handle-intro-period-end': {
        'task': 'subscription.tasks.expiry_handler.handle_intro_period_end',
        'schedule': crontab(hour=1, minute=45),
        'options': {'queue': 'celery'}
    },

    # Handle long delinquency - Daily at 2:30 AM
    # Auto-downgrade restricted subscriptions to free after SUBSCRIPTION_DELINQUENCY_DAYS
    # Industry standard: Gate actions during restricted, only downgrade after 90 days
    'handle-long-delinquency': {
        'task': 'subscription.tasks.expiry_handler.handle_long_delinquency',
        'schedule': crontab(hour=2, minute=30),
        'options': {'queue': 'celery'}
    },
}

# Logging Configuration with Rotation
# Prevents disk fill by rotating logs at 10MB, keeping 5 backups
LOGS_DIR = BASE_DIR / 'logs'
LOGS_DIR.mkdir(exist_ok=True)  # Create logs directory if it doesn't exist

LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'verbose': {
            'format': '{levelname} {asctime} {module} {process:d} {thread:d} {message}',
            'style': '{',
        },
        'simple': {
            'format': '{levelname} {asctime} {module}: {message}',
            'style': '{',
        },
        'celery': {
            'format': '[{asctime}] {levelname} {name}: {message}',
            'style': '{',
        },
    },
    'handlers': {
        # Django file handler with rotation
        'django_file': {
            'level': 'INFO',
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': LOGS_DIR / 'django.log',
            'maxBytes': 10 * 1024 * 1024,  # 10MB per file
            'backupCount': 5,               # Keep 5 old files (50MB total max)
            'formatter': 'simple',
        },
        # Celery file handler with rotation
        'celery_file': {
            'level': 'INFO',
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': LOGS_DIR / 'celery.log',
            'maxBytes': 10 * 1024 * 1024,  # 10MB per file
            'backupCount': 5,               # Keep 5 old files
            'formatter': 'celery',
        },
        # Error file - separate file for errors only
        'error_file': {
            'level': 'ERROR',
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': LOGS_DIR / 'errors.log',
            'maxBytes': 5 * 1024 * 1024,   # 5MB per file
            'backupCount': 10,              # Keep more error history
            'formatter': 'verbose',
        },
        # Console handler (dev only)
        'console': {
            'level': 'DEBUG',
            'class': 'logging.StreamHandler',
            'formatter': 'simple',
        },
    },
    'loggers': {
        'django': {
            'handlers': ['django_file', 'console', 'error_file'],
            'level': 'INFO',
            'propagate': True,
        },
        'django.request': {
            'handlers': ['django_file', 'error_file'],
            'level': 'WARNING',
            'propagate': False,
        },
        # Celery loggers
        'celery': {
            'handlers': ['celery_file', 'console', 'error_file'],
            'level': 'INFO',
            'propagate': False,
        },
        'celery.task': {
            'handlers': ['celery_file', 'console'],
            'level': 'INFO',
            'propagate': False,
        },
        'celery.beat': {
            'handlers': ['celery_file', 'console'],
            'level': 'INFO',
            'propagate': False,
        },
        # Application loggers
        'workspace': {
            'handlers': ['django_file', 'console'],
            'level': 'DEBUG',
            'propagate': True,
        },
        'workspace.sync': {
            'handlers': ['django_file', 'console'],
            'level': 'INFO',
            'propagate': True,
        },
        'subscription': {
            'handlers': ['django_file', 'celery_file', 'console'],
            'level': 'INFO',
            'propagate': False,
        },
        'payments': {
            'handlers': ['django_file', 'console', 'error_file'],
            'level': 'INFO',
            'propagate': False,
        },
        'security': {
            'handlers': ['django_file', 'console', 'error_file'],
            'level': 'WARNING',
            'propagate': True,
        },
        'notifications': {
            'handlers': ['django_file', 'console'],
            'level': 'INFO',
            'propagate': True,
        },
    },
}

# Theme Configuration
THEME_CDN_BASE_URL = config('THEME_CDN_BASE_URL', default='https://cdn.huzilerz.com')

# ============================================================================
# INFRASTRUCTURE CONFIGURATION (Shopify-style Pool Model)
# ============================================================================

# Infrastructure Mode: 'mock' (development) or 'aws' (production)
# - mock: Uses MockAWSService for local development (no AWS calls)
# - aws: Uses AWSInfrastructureService for production (real AWS resources)
INFRASTRUCTURE_MODE = config('INFRASTRUCTURE_MODE', default='mock')

# Wildcard DNS (Shopify Model)
# - True: One DNS record (*.huzilerz.com) for all workspaces (recommended)
# - False: Per-workspace DNS records (not recommended for pool model)
# IMPORTANT: Requires manual AWS Route53 setup (see documentation/todo.wildcardsetup.md)
USE_WILDCARD_DNS = config('USE_WILDCARD_DNS', default=True, cast=bool)

# CloudFront Behaviors
# - False: Application-level routing (recommended for pool model)
# - True: CloudFront-level routing (requires per-workspace cache behaviors)
SETUP_CLOUDFRONT_BEHAVIORS = config('SETUP_CLOUDFRONT_BEHAVIORS', default=False, cast=bool)

# Shared Pool Configuration
# All workspaces share these AWS resources (Shopify model)
# Workspace isolation via path-based routing: /workspaces/{workspace_id}/*
SHARED_POOL_CONFIG = {
    # CloudFront CDN (shared distribution)
    'cdn_distribution': config('SHARED_CLOUDFRONT_DISTRIBUTION_ID', default='E1234567890ABC'),
    'cdn_distribution_domain': config('CLOUDFRONT_DOMAIN', default='d123456abcdef.cloudfront.net'),

    # S3 Buckets (shared with folder-based isolation)
    'media_bucket': config('S3_MEDIA_BUCKET', default='shared-pool-media'),
    'storage_bucket': config('S3_STORAGE_BUCKET', default='shared-pool-storage'),

    # API Gateway (shared with path-based routing)
    'api_gateway': config('API_GATEWAY_ID', default='shared-api-gateway'),
}

# AWS Route53 Configuration
# Required for production (INFRASTRUCTURE_MODE='aws')
# Get this from AWS Console → Route53 → Hosted Zones
ROUTE53_HOSTED_ZONE_ID = config('ROUTE53_HOSTED_ZONE_ID', default=None)

# SSL Certificate Configuration
# Required for production wildcard SSL (*.huzilerz.com)
# Get this from AWS Console → Certificate Manager → Certificates
SHARED_SSL_CERTIFICATE_ARN = config('SSL_CERTIFICATE_ARN', default=None)

# AWS Region
AWS_DEFAULT_REGION = config('AWS_DEFAULT_REGION', default='us-east-1')  # Must be us-east-1 for CloudFront

# AWS Credentials (for boto3)
# Get these from AWS Console → IAM → Users → Security Credentials
AWS_ACCESS_KEY_ID = config('AWS_ACCESS_KEY_ID', default=None)
AWS_SECRET_ACCESS_KEY = config('AWS_SECRET_ACCESS_KEY', default=None)

# Production Validation
# Set to True in production to enforce infrastructure validation on startup
VALIDATE_INFRASTRUCTURE_ON_STARTUP = config('VALIDATE_INFRASTRUCTURE_ON_STARTUP', default=False, cast=bool)

# ============================================================================
# POSTHOG ANALYTICS CONFIGURATION
# ============================================================================

# PostHog Integration
# Used for advanced analytics, funnels, session replay
# Set POSTHOG_ENABLED=True in .env to enable
POSTHOG_ENABLED = config('POSTHOG_ENABLED', default=False, cast=bool)
POSTHOG_API_KEY = config('POSTHOG_API_KEY', default='')
POSTHOG_HOST = config('POSTHOG_HOST', default='https://app.posthog.com')

# PostHog settings are only loaded if POSTHOG_ENABLED=True
# This ensures no tracking happens in development unless explicitly enabled

# ============================================================================
# SUBSCRIPTION DELINQUENCY CONFIGURATION
# ============================================================================

# Days of inactivity in restricted status before auto-downgrade to free
# Industry standard: 60-90 days (configurable via .env)
# Reference: gem.md - "Downgrade only after long inactivity (60-90 days unpaid)"
SUBSCRIPTION_DELINQUENCY_DAYS = config('SUBSCRIPTION_DELINQUENCY_DAYS', default=90, cast=int)
